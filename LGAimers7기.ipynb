{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 라이브러리 임포트\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "import xgboost as xgb"
      ],
      "metadata": {
        "id": "zEu1yJEuzMQD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  날짜 기반 파생변수 생성 함수\n",
        "def make_date_feats(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    날짜 컬럼(영업일자)으로부터 다양한 달력 기반 변수 생성\n",
        "    - 연, 월, 일, 요일, 주말 여부\n",
        "    - 월/요일을 주기적으로 표현하는 sin, cos 값\n",
        "    - 일(dayofyear) 기반 계절성 표현\n",
        "    - 주차(weekofyear), 월 시작/종료 여부\n",
        "    \"\"\"\n",
        "    df_c = df.copy()\n",
        "    dt = pd.to_datetime(df_c[\"영업일자\"])\n",
        "\n",
        "    # 기본 날짜 정보\n",
        "    df_c[\"year\"] = dt.dt.year\n",
        "    df_c[\"month\"] = dt.dt.month\n",
        "    df_c[\"day\"] = dt.dt.day\n",
        "    df_c[\"weekday\"] = dt.dt.weekday\n",
        "    df_c[\"is_weekend\"] = df_c[\"weekday\"].isin([5, 6]).astype(int)\n",
        "\n",
        "    # 주기적 패턴 (sin, cos 인코딩)\n",
        "    df_c[\"month_sin\"] = np.sin(2*np.pi*df_c[\"month\"]/12.0)\n",
        "    df_c[\"month_cos\"] = np.cos(2*np.pi*df_c[\"month\"]/12.0)\n",
        "    df_c[\"wday_sin\"] = np.sin(2*np.pi*df_c[\"weekday\"]/7.0)\n",
        "    df_c[\"wday_cos\"] = np.cos(2*np.pi*df_c[\"weekday\"]/7.0)\n",
        "\n",
        "    # 1년 중 며칠째인지\n",
        "    df_c[\"doy\"] = dt.dt.dayofyear\n",
        "    df_c[\"doy_sin\"] = np.sin(2*np.pi*df_c[\"doy\"]/365)\n",
        "    df_c[\"doy_cos\"] = np.cos(2*np.pi*df_c[\"doy\"]/365)\n",
        "\n",
        "    # 주차 정보, 월 시작/끝 여부\n",
        "    df_c[\"weekofyear\"] = dt.dt.isocalendar().week.astype(int)\n",
        "    df_c[\"is_month_start\"] = dt.dt.is_month_start.astype(int)\n",
        "    df_c[\"is_month_end\"] = dt.dt.is_month_end.astype(int)\n",
        "\n",
        "    return df_c"
      ],
      "metadata": {
        "id": "9Xk8mzn_zZ6T"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  학습 단계에서 사용할 지연/롤링 피처\n",
        "#   - 과거 매출로부터 규칙적으로 파생변수 생성\n",
        "def add_train_lag_roll_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    item_id(상품)별로 정렬 후, 과거 정보로 다양한 피처를 만듭니다.\n",
        "    - lag: 어제/7일전/14일전/28일전 매출\n",
        "    - rolling: 최근 7/14/28일 평균/표준편차/중앙값, 최솟값/최댓값\n",
        "    - zeros: 최근 N일 동안 매출이 0인 날 수\n",
        "    - days_since_nz: 마지막 '0이 아닌 매출' 이후 며칠 지났는지\n",
        "    - trend7: 최근 7일의 선형 추세(기울기)\n",
        "    - same weekday rolling: 같은 요일 기준 최근 4회 평균\n",
        "    - ratio/volatility: 비율, 변동성 지표\n",
        "    \"\"\"\n",
        "    df = df.sort_values([\"item_id\",\"영업일자\"]).copy()\n",
        "    g = df.groupby(\"item_id\")[\"매출수량\"]\n",
        "\n",
        "    # 1) 지연 변수(lag)\n",
        "    for lag in [1, 7, 14, 28]:\n",
        "        df[f\"lag{lag}\"] = g.shift(lag)\n",
        "\n",
        "    # 2) 기본 롤링 통계\n",
        "    df[\"roll7_mean\"]   = g.shift(1).rolling(7).mean()\n",
        "    df[\"roll14_mean\"]  = g.shift(1).rolling(14).mean()\n",
        "    df[\"roll7_std\"]    = g.shift(1).rolling(7).std()\n",
        "    df[\"roll7_median\"] = g.shift(1).rolling(7).median()\n",
        "\n",
        "    # 3) 28일 최솟값/최댓값\n",
        "    df[\"min28\"] = g.shift(1).rolling(28).min()\n",
        "    df[\"max28\"] = g.shift(1).rolling(28).max()\n",
        "\n",
        "    # 4) 최근 N일간 0인 날 수\n",
        "    z = (df[\"매출수량\"] == 0).astype(int)\n",
        "    gz = df.assign(zflag=z).groupby(\"item_id\")[\"zflag\"]\n",
        "    df[\"zeros7\"]  = gz.shift(1).rolling(7).sum()\n",
        "    df[\"zeros14\"] = gz.shift(1).rolling(14).sum()\n",
        "    df[\"zeros28\"] = gz.shift(1).rolling(28).sum()\n",
        "\n",
        "    # 5) 마지막 '0이 아닌 매출' 이후 경과일수 (최대 60으로 클리핑)\n",
        "    def _dsls(series: pd.Series) -> pd.Series:\n",
        "        prev = series.shift(1).fillna(0).values\n",
        "        out = np.zeros_like(prev, dtype=float)\n",
        "        cnt = 0\n",
        "        for i, v in enumerate(prev):\n",
        "            if v > 0:\n",
        "                cnt = 0\n",
        "            else:\n",
        "                cnt += 1\n",
        "            out[i] = cnt\n",
        "        out = np.clip(out, 0, 60)\n",
        "        return pd.Series(out, index=series.index)\n",
        "    df[\"days_since_nz\"] = df.groupby(\"item_id\")[\"매출수량\"].transform(_dsls)\n",
        "\n",
        "    # 6) 최근 7일 선형추세 기울기(상승/하강 경향)\n",
        "    def _trend_7(x: pd.Series) -> float:\n",
        "        if x.isna().sum() > 0:\n",
        "            return np.nan\n",
        "        y = x.values.astype(float)\n",
        "        x_idx = np.arange(len(y))\n",
        "        return np.polyfit(x_idx, y, 1)[0]\n",
        "    df[\"trend7\"] = g.shift(1).rolling(7).apply(lambda s: _trend_7(s), raw=False)\n",
        "\n",
        "    # 7) 같은 요일 기준 최근 4회 평균\n",
        "    df[\"weekday\"] = pd.to_datetime(df[\"영업일자\"]).dt.weekday\n",
        "    grp = df.groupby([\"item_id\",\"weekday\"])[\"매출수량\"]\n",
        "    df[\"weekday_roll4_mean\"] = grp.shift(1).rolling(4).mean()\n",
        "\n",
        "    # 8) 비율/변동성\n",
        "    df[\"lag1_div_lag7\"]   = df[\"lag1\"] / (df[\"lag7\"] + 1e-6)\n",
        "    df[\"lag1_minus_lag7\"] = df[\"lag1\"] - df[\"lag7\"]\n",
        "    df[\"vol7\"]            = df[\"roll7_std\"] / (df[\"roll7_mean\"] + 1e-6)\n",
        "\n",
        "    # 9) mean28 기반 비율\n",
        "    df[\"mean28\"]             = g.shift(1).rolling(28).mean()\n",
        "    df[\"lag1_div_mean28\"]    = df[\"lag1\"] / (df[\"mean28\"] + 1e-6)\n",
        "    df[\"lag7_div_mean28\"]    = df[\"lag7\"] / (df[\"mean28\"] + 1e-6)\n",
        "    df[\"roll7_div_mean28\"]   = df[\"roll7_mean\"] / (df[\"mean28\"] + 1e-6)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "xfugXX6xJ_F9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  EWM/장기 롤링/분위수 기반 피처 (학습 단계)\n",
        "def add_ewm_long_quant_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    - EWM: 최근 데이터에 더 큰 가중치(변화에 민감)\n",
        "    - 장기 롤링 평균: 60/90일\n",
        "    - 분위수(25%, 75%)와 분위수 비율(cv28)\n",
        "    + item별 평균/전체 평균으로 결측 안전 채움\n",
        "    \"\"\"\n",
        "    df = df.sort_values([\"item_id\",\"영업일자\"]).copy()\n",
        "    g = df.groupby(\"item_id\")[\"매출수량\"]\n",
        "\n",
        "    # EWM (최근 가중치 ↑)\n",
        "    df[\"ewm7\"]    = g.shift(1).ewm(span=7, adjust=False).mean()\n",
        "    df[\"ewm28\"]   = g.shift(1).ewm(span=28, adjust=False).mean()\n",
        "    df[\"ewm7_std\"] = g.shift(1).ewm(span=7, adjust=False).std()\n",
        "\n",
        "    # 장기 롤링 평균\n",
        "    df[\"roll60_mean\"] = g.shift(1).rolling(60, min_periods=10).mean()\n",
        "    df[\"roll90_mean\"] = g.shift(1).rolling(90, min_periods=15).mean()\n",
        "\n",
        "    # 분위수\n",
        "    df[\"roll28_q25\"] = g.shift(1).rolling(28, min_periods=7).quantile(0.25)\n",
        "    df[\"roll28_q75\"] = g.shift(1).rolling(28, min_periods=7).quantile(0.75)\n",
        "\n",
        "    # 분위수 비율 기반 변동성\n",
        "    df[\"cv28\"] = df[\"roll28_q75\"] / (df[\"roll28_q25\"] + 1e-6)\n",
        "\n",
        "    # 안전 채움\n",
        "    add_cols = [\"ewm7\",\"ewm28\",\"ewm7_std\",\"roll60_mean\",\"roll90_mean\",\"roll28_q25\",\"roll28_q75\",\"cv28\"]\n",
        "    df = safe_fillna_by_item(df, add_cols)\n",
        "    return df"
      ],
      "metadata": {
        "id": "8dbhOwYYKAHP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  안전한 결측치 채움 (item_id 단위)\n",
        "#   - item별 평균 -> 전체 평균 -> 0 순으로 채움\n",
        "def safe_fillna_by_item(df: pd.DataFrame, cols: list) -> pd.DataFrame:\n",
        "    out = df.copy()\n",
        "    if \"item_id\" not in out.columns:\n",
        "        raise KeyError(\"safe_fillna_by_item requires an 'item_id' column\")\n",
        "    out = out.loc[:, ~out.columns.duplicated()].copy()\n",
        "    for c in cols:\n",
        "        item_means = out.groupby(\"item_id\")[c].transform(lambda s: s.fillna(s.mean()))\n",
        "        out[c] = out[c].fillna(item_means)\n",
        "        out[c] = out[c].fillna(out[c].mean()).fillna(0.0)\n",
        "    return out"
      ],
      "metadata": {
        "id": "oXKA2bAJKES0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  모델 입력 피처 목록 (캘린더 + 지연/롤링 + 비율/변동성 + EWM/분위수)\n",
        "FEATURE_COLS = [\n",
        "    # calendar\n",
        "    \"year\",\"month\",\"day\",\"weekday\",\"is_weekend\",\n",
        "    \"month_sin\",\"month_cos\",\"wday_sin\",\"wday_cos\",\n",
        "    \"doy\",\"doy_sin\",\"doy_cos\",\"weekofyear\",\"is_month_start\",\"is_month_end\",\n",
        "    # id\n",
        "    \"item_id\",\n",
        "    # lags\n",
        "    \"lag1\",\"lag7\",\"lag14\",\"lag28\",\n",
        "    # roll stats\n",
        "    \"roll7_mean\",\"roll14_mean\",\"roll7_std\",\"roll7_median\",\n",
        "    \"min28\",\"max28\",\n",
        "    # zeros & dsls\n",
        "    \"zeros7\",\"zeros14\",\"zeros28\",\"days_since_nz\",\n",
        "    # trend & weekday mean\n",
        "    \"trend7\",\"weekday_roll4_mean\",\n",
        "    # ratios & vol\n",
        "    \"lag1_div_lag7\",\"lag1_minus_lag7\",\"vol7\",\n",
        "    \"lag1_div_mean28\",\"lag7_div_mean28\",\"roll7_div_mean28\",\n",
        "]\n",
        "FEATURE_COLS += [\n",
        "    \"ewm7\",\"ewm28\",\"ewm7_std\",\"roll60_mean\",\"roll90_mean\",\"roll28_q25\",\"roll28_q75\",\"cv28\"\n",
        "]"
      ],
      "metadata": {
        "id": "7HkocvfTKGhF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  데이터 로드 & 기본 전처리\n",
        "print(\"Loading train...\")\n",
        "train = pd.read_csv(\"train.csv\")\n",
        "train[\"영업일자\"] = pd.to_datetime(train[\"영업일자\"])\n",
        "\n",
        "# 범주형 → 숫자 라벨 (상품명+메뉴명 조합을 item_id로)\n",
        "le = LabelEncoder()\n",
        "train[\"item_id\"] = le.fit_transform(train[\"영업장명_메뉴명\"])\n",
        "\n",
        "# 캘린더 파생변수\n",
        "train = make_date_feats(train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1ei9XjvKLCf",
        "outputId": "d12231ae-f7f2-4f4c-be50-f40f91fcd66e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading train...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  IQR 기반 이상치(극단값) 완화\n",
        "#   - 실제 0은 유지, 0 초과 값만 IQR으로 완화\n",
        "def handle_outliers_iqr(df_group: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    각 item(영업장명_메뉴명) 그룹 내에서\n",
        "    - 매출수량 > 0인 값에 대해 IQR 범위 밖이면 클리핑\n",
        "    \"\"\"\n",
        "    non_zero = df_group[df_group[\"매출수량\"] > 0][\"매출수량\"]\n",
        "    if len(non_zero) < 5:\n",
        "        return df_group  # 표본이 너무 적으면 패스\n",
        "    q1, q3 = non_zero.quantile(0.25), non_zero.quantile(0.75)\n",
        "    iqr = q3 - q1\n",
        "    lower, upper = max(0, q1 - 1.5*iqr), q3 + 1.5*iqr\n",
        "    df_group[\"매출수량\"] = np.clip(df_group[\"매출수량\"], lower, upper)\n",
        "    return df_group\n",
        "\n",
        "# item 단위로 이상치 처리\n",
        "train = train.groupby(\"영업장명_메뉴명\", group_keys=False).apply(handle_outliers_iqr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pY4gzemtKMZq",
        "outputId": "c2868b3e-0612-41f2-ee02-108c2b52735b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-901663974.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  train = train.groupby(\"영업장명_메뉴명\", group_keys=False).apply(handle_outliers_iqr)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  학습 피처 생성 (학습 데이터 전용 함수)\n",
        "train = add_train_lag_roll_features(train)\n",
        "train = add_ewm_long_quant_features(train)\n",
        "\n",
        "# 모델 입력/타깃 구성 + 결측치 제거\n",
        "X_all = train[FEATURE_COLS].copy()\n",
        "y_all = train[\"매출수량\"].astype(float)\n",
        "\n",
        "mask = X_all.notna().all(axis=1)\n",
        "X_all = X_all[mask]\n",
        "y_all = y_all[mask]\n",
        "\n",
        "print(f\"Train matrix: {X_all.shape}, target: {y_all.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvNiDdeMKOTm",
        "outputId": "cae846fc-bfd5-415b-8534-86b3701c9611"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train matrix: (97272, 46), target: (97272,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  XGBoost 앙상블 학습\n",
        "#   - 타임시리즈 스플릿으로 마지막 fold에서 조기중단 길이(best_iter) 추정\n",
        "#   - 전체 데이터로 best_iter만큼 다시 학습 → 앙상블 리스트에 저장\n",
        "try:\n",
        "    import torch\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "except Exception:\n",
        "    device = \"cpu\"\n",
        "\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "boosters, best_iters = [], []\n",
        "\n",
        "for seed, max_depth in [(42, 6), (13, 8), (77, 10), (101, 6)]:\n",
        "    params = {\n",
        "        \"objective\": \"reg:squarederror\",\n",
        "        \"eval_metric\": \"rmse\",\n",
        "        \"tree_method\": \"hist\",\n",
        "        \"device\": device,\n",
        "        \"learning_rate\": 0.05,\n",
        "        \"subsample\": 0.9,\n",
        "        \"colsample_bytree\": 0.9,\n",
        "        \"max_depth\": max_depth,\n",
        "        \"gamma\": 0.0,\n",
        "        \"lambda\": 1.0,\n",
        "        \"alpha\": 0.0,\n",
        "        \"seed\": seed,\n",
        "    }\n",
        "\n",
        "    # 마지막 fold를 검증셋으로 사용 (보수적 조기중단)\n",
        "    last_tr_idx, last_va_idx = list(tscv.split(X_all))[-1]\n",
        "    dtr = xgb.DMatrix(X_all.iloc[last_tr_idx], label=y_all.iloc[last_tr_idx])\n",
        "    dva = xgb.DMatrix(X_all.iloc[last_va_idx], label=y_all.iloc[last_va_idx])\n",
        "\n",
        "    booster = xgb.train(\n",
        "        params,\n",
        "        dtr,\n",
        "        num_boost_round=5000,\n",
        "        evals=[(dva, \"val\")],\n",
        "        early_stopping_rounds=100,\n",
        "        verbose_eval=False\n",
        "    )\n",
        "    best_iter = booster.best_iteration\n",
        "\n",
        "    # 전체 데이터로 best_iter만큼 재학습 (과적합 방지)\n",
        "    dall = xgb.DMatrix(X_all, label=y_all)\n",
        "    booster_full = xgb.train(params, dall, num_boost_round=best_iter, verbose_eval=False)\n",
        "\n",
        "    boosters.append(booster_full)\n",
        "    best_iters.append(best_iter)\n",
        "\n",
        "print(\"Ensemble trained. Best iterations per model:\", best_iters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuIfXhH8KQ-n",
        "outputId": "17d2649d-92bc-46e6-f000-1f805f4eee22"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble trained. Best iterations per model: [72, 95, 109, 144]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  앙상블 예측 함수 (여러 모델 평균)\n",
        "def predict_ensemble(boosters, X_pred: pd.DataFrame) -> np.ndarray:\n",
        "    dpred = xgb.DMatrix(X_pred)\n",
        "    preds = [bst.predict(dpred) for bst in boosters]\n",
        "    return np.mean(preds, axis=0)"
      ],
      "metadata": {
        "id": "zftaCKg_KTfm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  테스트/예측 시점의 피처 생성 (미래 누수 방지)\n",
        "#   - target_date에 대해 오직 과거 정보만 써서 피처를 만든 뒤 예측\n",
        "print(\"Loading sample & tests...\")\n",
        "sample = pd.read_csv(\"sample_submission.csv\")\n",
        "\n",
        "tests = {}\n",
        "for i in range(10):\n",
        "    name = f\"TEST_{i:02d}\"\n",
        "    df = pd.read_csv(f\"{name}.csv\")\n",
        "    df[\"영업일자\"] = pd.to_datetime(df[\"영업일자\"])\n",
        "    tests[name] = df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZCkbIa6KVkk",
        "outputId": "2c87280e-985a-49f1-ba51-43fe0c5f4b2f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading sample & tests...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_step_features(history: pd.DataFrame, target_date: pd.Timestamp):\n",
        "    \"\"\"\n",
        "    target_date 하루치 예측에 필요한 피처를 만든 뒤 (frame),\n",
        "    FEATURE_COLS만 추출해 X_pred로 반환합니다.\n",
        "    (누수 방지: 모든 롤링/ewm/분위수는 과거 데이터만 기반)\n",
        "    \"\"\"\n",
        "    # 1) 예측 대상 아이템 목록 프레임\n",
        "    items = history[\"영업장명_메뉴명\"].unique()\n",
        "    frame = pd.DataFrame({\n",
        "        \"영업일자\": np.repeat(target_date, len(items)),\n",
        "        \"영업장명_메뉴명\": items\n",
        "    })\n",
        "\n",
        "    # item_id 매핑\n",
        "    frame[\"item_id\"] = (\n",
        "        history.drop_duplicates(\"영업장명_메뉴명\")\n",
        "               .set_index(\"영업장명_메뉴명\")[\"item_id\"]\n",
        "               .reindex(items).values\n",
        "    )\n",
        "\n",
        "    # 캘린더 파생\n",
        "    frame = make_date_feats(frame)\n",
        "\n",
        "    # 작업용 과거 히스토리\n",
        "    temp_hist = history.copy()\n",
        "\n",
        "    # -------------------------\n",
        "    # Lag (미래 누수 방지: 날짜를 lag만큼 +)\n",
        "    # -------------------------\n",
        "    for lag in [1, 7, 14, 28]:\n",
        "        lagged = temp_hist[[\"영업일자\",\"item_id\",\"매출수량\"]].copy()\n",
        "        lagged[\"영업일자\"] = lagged[\"영업일자\"] + pd.Timedelta(days=lag)\n",
        "        frame = frame.merge(\n",
        "            lagged.rename(columns={\"매출수량\": f\"lag{lag}\"}),\n",
        "            on=[\"영업일자\",\"item_id\"], how=\"left\"\n",
        "        )\n",
        "\n",
        "    # -------------------------\n",
        "    # Rolling/집계 (과거만 사용)\n",
        "    # -------------------------\n",
        "    roll_base = temp_hist.sort_values([\"item_id\",\"영업일자\"]).copy()\n",
        "    gb = roll_base.groupby(\"item_id\")[\"매출수량\"]\n",
        "\n",
        "    roll_base[\"roll7_mean\"]   = gb.rolling(7).mean().reset_index(0, drop=True)\n",
        "    roll_base[\"roll14_mean\"]  = gb.rolling(14).mean().reset_index(0, drop=True)\n",
        "    roll_base[\"roll7_std\"]    = gb.rolling(7).std().reset_index(0, drop=True)\n",
        "    roll_base[\"roll7_median\"] = gb.rolling(7).median().reset_index(0, drop=True)\n",
        "    roll_base[\"min28\"]        = gb.rolling(28).min().reset_index(0, drop=True)\n",
        "    roll_base[\"max28\"]        = gb.rolling(28).max().reset_index(0, drop=True)\n",
        "    roll_base[\"mean28\"]       = gb.rolling(28).mean().reset_index(0, drop=True)\n",
        "\n",
        "    # 최근 N일 0 카운트\n",
        "    roll_base[\"zflag\"] = (roll_base[\"매출수량\"] == 0).astype(int)\n",
        "    gzz = roll_base.groupby(\"item_id\")[\"zflag\"]\n",
        "    roll_base[\"zeros7\"]  = gzz.rolling(7).sum().reset_index(0, drop=True)\n",
        "    roll_base[\"zeros14\"] = gzz.rolling(14).sum().reset_index(0, drop=True)\n",
        "    roll_base[\"zeros28\"] = gzz.rolling(28).sum().reset_index(0, drop=True)\n",
        "\n",
        "    # EWM/장기/분위수\n",
        "    roll_base[\"ewm7\"] = gb.apply(lambda s: s.ewm(span=7, adjust=False).mean()).reset_index(0, drop=True)\n",
        "    roll_base[\"ewm28\"] = gb.apply(lambda s: s.ewm(span=28, adjust=False).mean()).reset_index(0, drop=True)\n",
        "    roll_base[\"ewm7_std\"] = gb.apply(lambda s: s.ewm(span=7, adjust=False).std()).reset_index(0, drop=True)\n",
        "\n",
        "    roll_base[\"roll60_mean\"] = gb.rolling(60, min_periods=10).mean().reset_index(0, drop=True)\n",
        "    roll_base[\"roll90_mean\"] = gb.rolling(90, min_periods=15).mean().reset_index(0, drop=True)\n",
        "\n",
        "    roll_base[\"roll28_q25\"] = gb.rolling(28, min_periods=7).quantile(0.25).reset_index(0, drop=True)\n",
        "    roll_base[\"roll28_q75\"] = gb.rolling(28, min_periods=7).quantile(0.75).reset_index(0, drop=True)\n",
        "\n",
        "    # 하루 당겨서(+1day) target_date와 align → 누수 방지\n",
        "    roll_base[\"영업일자\"] = roll_base[\"영업일자\"] + pd.Timedelta(days=1)\n",
        "    frame = frame.merge(\n",
        "        roll_base[[\n",
        "            \"영업일자\",\"item_id\",\n",
        "            \"roll7_mean\",\"roll14_mean\",\"roll7_std\",\"roll7_median\",\n",
        "            \"min28\",\"max28\",\"mean28\",\n",
        "            \"zeros7\",\"zeros14\",\"zeros28\",\n",
        "            \"ewm7\",\"ewm28\",\"ewm7_std\",\n",
        "            \"roll60_mean\",\"roll90_mean\",\n",
        "            \"roll28_q25\",\"roll28_q75\",\n",
        "        ]],\n",
        "        on=[\"영업일자\",\"item_id\"], how=\"left\"\n",
        "    )\n",
        "\n",
        "    # 마지막 비-제로 매출 이후 경과일(최근 28일 관찰)\n",
        "    def dsls_for_item(iid: int) -> float:\n",
        "        h = temp_hist[temp_hist[\"item_id\"] == iid].sort_values(\"영업일자\").tail(28)\n",
        "        h_nz = h[h[\"매출수량\"] > 0]\n",
        "        if len(h_nz) == 0:\n",
        "            return 60.0\n",
        "        last_nz = h_nz[\"영업일자\"].max()\n",
        "        return float(min(60, (pd.to_datetime(target_date - pd.Timedelta(days=1)) - last_nz).days))\n",
        "\n",
        "    frame[\"days_since_nz\"] = frame[\"item_id\"].map(dsls_for_item)\n",
        "\n",
        "    # trend7 (최근 7일 기울기)\n",
        "    def compute_trend7_per_item(item_id):\n",
        "        h = temp_hist[temp_hist[\"item_id\"] == item_id].sort_values(\"영업일자\")[\"매출수량\"].values[-7:]\n",
        "        if len(h) < 7 or np.isnan(h).any():\n",
        "            return np.nan\n",
        "        x = np.arange(7)\n",
        "        return np.polyfit(x, h.astype(float), 1)[0]\n",
        "    frame[\"trend7\"] = frame[\"item_id\"].map(lambda iid: compute_trend7_per_item(iid))\n",
        "\n",
        "    # 같은 요일 기준 최근 4회 평균\n",
        "    temp_hist[\"weekday\"] = pd.to_datetime(temp_hist[\"영업일자\"]).dt.weekday\n",
        "    target_wday = pd.to_datetime(target_date).weekday()\n",
        "\n",
        "    def same_weekday_last4_mean(iid):\n",
        "        h = temp_hist[(temp_hist[\"item_id\"] == iid) & (temp_hist[\"weekday\"] == target_wday)] \\\n",
        "                .sort_values(\"영업일자\")[\"매출수량\"].tail(4)\n",
        "        if len(h) == 0:\n",
        "            return np.nan\n",
        "        return float(h.mean())\n",
        "\n",
        "    frame[\"weekday_roll4_mean\"] = frame[\"item_id\"].map(same_weekday_last4_mean)\n",
        "\n",
        "    # 비율/변동성 + 분위수 기반 변동성(cv28)\n",
        "    frame[\"lag1_div_lag7\"]     = frame[\"lag1\"] / (frame[\"lag7\"] + 1e-6)\n",
        "    frame[\"lag1_minus_lag7\"]   = frame[\"lag1\"] - frame[\"lag7\"]\n",
        "    frame[\"vol7\"]              = frame[\"roll7_std\"] / (frame[\"roll7_mean\"] + 1e-6)\n",
        "    frame[\"lag1_div_mean28\"]   = frame[\"lag1\"] / (frame[\"mean28\"] + 1e-6)\n",
        "    frame[\"lag7_div_mean28\"]   = frame[\"lag7\"] / (frame[\"mean28\"] + 1e-6)\n",
        "    frame[\"roll7_div_mean28\"]  = frame[\"roll7_mean\"] / (frame[\"mean28\"] + 1e-6)\n",
        "    frame[\"cv28\"]              = frame[\"roll28_q75\"] / (frame[\"roll28_q25\"] + 1e-6)\n",
        "\n",
        "    # 최종 입력행 구성 + 결측 안전 처리\n",
        "    X_pred_full = frame[FEATURE_COLS].copy()\n",
        "    X_pred_full = X_pred_full.loc[:, ~X_pred_full.columns.duplicated()].copy()\n",
        "    X_pred_full = safe_fillna_by_item(X_pred_full, cols=[c for c in FEATURE_COLS if c != \"item_id\"])\n",
        "    X_pred = X_pred_full[FEATURE_COLS]\n",
        "    return X_pred, frame"
      ],
      "metadata": {
        "id": "ZzT3258vKXd8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  7일 재귀 예측 (하루 예측 → 히스토리에 반영 → 다음날 예측)\n",
        "all_preds = []\n",
        "\n",
        "for test_name, test_df in tests.items():\n",
        "    test_df = test_df.copy()\n",
        "    test_df[\"item_id\"] = le.transform(test_df[\"영업장명_메뉴명\"])\n",
        "    test_df = make_date_feats(test_df)\n",
        "\n",
        "    # 예측 시작용 히스토리(테스트의 과거 관측)\n",
        "    history = test_df.sort_values([\"item_id\",\"영업일자\"]).copy()\n",
        "    last_date = history[\"영업일자\"].max()\n",
        "\n",
        "    preds_rows = []\n",
        "    current_date = last_date\n",
        "\n",
        "    for step in range(1, 8):  # 7-step\n",
        "        target_date = current_date + pd.Timedelta(days=1)\n",
        "\n",
        "        # 1) 피처 만들기(누수 방지)\n",
        "        X_pred, frame = build_step_features(history, target_date)\n",
        "\n",
        "        # 2) 앙상블 예측\n",
        "        yhat = predict_ensemble(boosters, X_pred)\n",
        "        yhat = np.clip(yhat, 0, None)  # 음수 방지\n",
        "\n",
        "        # 3) 히스토리에 예측값을 추가(재귀)\n",
        "        add_hist = frame[[\"영업일자\",\"item_id\",\"영업장명_메뉴명\"]].copy()\n",
        "        add_hist[\"매출수량\"] = yhat\n",
        "        history = pd.concat([history, add_hist], ignore_index=True)\n",
        "\n",
        "        # 4) 제출용 행 축적\n",
        "        out_row = frame[[\"영업일자\",\"영업장명_메뉴명\"]].copy()\n",
        "        out_row[\"pred\"] = yhat\n",
        "        out_row[\"영업일자\"] = f\"{test_name}+{step}일\"\n",
        "        preds_rows.append(out_row)\n",
        "\n",
        "        current_date = target_date\n",
        "\n",
        "    # TEST 파일 하나에 대한 wide 형태 예측\n",
        "    test_pred = pd.concat(preds_rows, ignore_index=True)\n",
        "    wide = test_pred.pivot(index=\"영업일자\", columns=\"영업장명_메뉴명\", values=\"pred\")\n",
        "    all_preds.append(wide)"
      ],
      "metadata": {
        "id": "wX_HVbEgKj7v"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  반올림 후 0 → 1 치환\n",
        "#   - 대회 규칙/전략에 따라 설정\n",
        "all_preds = [df.round(0).replace(0, 1) for df in all_preds]"
      ],
      "metadata": {
        "id": "tpzxRrDUKmrf"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sArO7FUMPKRm",
        "outputId": "f348b4bb-8dc8-494c-9499-3c6b9dce9f97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved\n"
          ]
        }
      ],
      "source": [
        "submission = pd.concat(all_preds)\n",
        "submission = submission.reset_index().rename(columns={\"index\": \"영업일자\"})\n",
        "sample = pd.read_csv(\"sample_submission.csv\")\n",
        "submission = submission[sample.columns]\n",
        "\n",
        "submission.to_csv(\"EWM_submission.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "print(f\"✅ Saved\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GxHIBDRV1DVM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}